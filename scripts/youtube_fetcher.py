#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube è§†é¢‘è·å–æ¨¡å—
è·å– Elon Musk, Jensen Huang ç­‰ç§‘æŠ€é¢†è¢–çš„æœ€æ–°è®¿è°ˆè§†é¢‘
"""

import os
import json
import re
import urllib.request
import urllib.parse
from datetime import datetime, timedelta
from dataclasses import dataclass
from typing import List, Optional, Dict


@dataclass
class YouTubeVideo:
    """YouTube è§†é¢‘æ•°æ®ç»“æ„"""
    video_id: str
    title: str
    description: str
    channel_title: str
    published_at: str
    thumbnail_url: str
    duration: Optional[str] = None
    duration_seconds: Optional[int] = None
    view_count: Optional[str] = None
    
    @property
    def watch_url(self) -> str:
        return f"https://www.youtube.com/watch?v={self.video_id}"
    
    @property
    def embed_url(self) -> str:
        return f"https://www.youtube.com/embed/{self.video_id}"


class YouTubeFetcher:
    """YouTube è§†é¢‘æŠ“å–å™¨"""
    
    BASE_URL = "https://www.googleapis.com/youtube/v3"
    
    # é…é¢æˆæœ¬å¸¸é‡
    QUOTA_COST_SEARCH = 100
    QUOTA_COST_VIDEOS = 1
    
    # ç§‘æŠ€é¢†è¢–æœç´¢å…³é”®è¯
    TECH_LEADERS = {
        "Elon Musk": [
            "Elon Musk interview 2024",
            "Elon Musk talk",
            "Elon Musk podcast",
            "Elon Musk AI",
            "Elon Musk Tesla",
            "Elon Musk SpaceX",
            "Elon Musk xAI",
        ],
        "Jensen Huang": [
            "Jensen Huang interview 2024",
            "Jensen Huang keynote",
            "Jensen Huang NVIDIA",
            "Jensen Huang AI",
            "Jensen Huang talk",
            "Jensen Huang GTC",
        ],
        "Sam Altman": [
            "Sam Altman interview 2024",
            "Sam Altman OpenAI",
            "Sam Altman talk",
            "Sam Altman podcast",
            "Sam Altman AI",
        ],
        "Satya Nadella": [
            "Satya Nadella interview 2024",
            "Satya Nadella Microsoft",
            "Satya Nadella AI",
            "Satya Nadella talk",
        ],
        "Sundar Pichai": [
            "Sundar Pichai interview 2024",
            "Sundar Pichai Google",
            "Sundar Pichai AI",
            "Sundar Pichai Gemini",
        ],
        "Mark Zuckerberg": [
            "Mark Zuckerberg interview 2024",
            "Mark Zuckerberg Meta",
            "Mark Zuckerberg AI",
            "Mark Zuckerberg Llama",
        ],
    }
    
    # çŸ¥åç§‘æŠ€è®¿è°ˆé¢‘é“
    TECH_CHANNELS = [
        "Lex Fridman",
        "All-In Podcast",
        "CNBC",
        "Bloomberg Technology",
        "TED",
        "Y Combinator",
    ]
    
    def __init__(self, api_key: Optional[str] = None, max_results: int = 10):
        self.api_key = api_key or os.getenv('YOUTUBE_API_KEY')
        self.max_results = max_results
        self.total_quota_used = 0
        self.request_count = 0
        self.request_log = []
    
    def _make_request(self, endpoint: str, params: dict) -> dict:
        """å‘é€ API è¯·æ±‚"""
        if not self.api_key:
            raise ValueError("éœ€è¦è®¾ç½® YOUTUBE_API_KEY ç¯å¢ƒå˜é‡")
        
        # è®°å½•é…é¢æ¶ˆè€—
        quota_cost = 0
        if 'search' in endpoint:
            quota_cost = self.QUOTA_COST_SEARCH
        elif 'videos' in endpoint:
            quota_cost = self.QUOTA_COST_VIDEOS
            
        self.total_quota_used += quota_cost
        self.request_count += 1
        self.request_log.append({
            'endpoint': endpoint,
            'cost': quota_cost,
            'time': datetime.now().isoformat()
        })
        
        params['key'] = self.api_key
        url = f"{self.BASE_URL}/{endpoint}?{urllib.parse.urlencode(params)}"
        
        try:
            with urllib.request.urlopen(url, timeout=30) as response:
                return json.loads(response.read().decode('utf-8'))
        except urllib.error.HTTPError as e:
            error_body = e.read().decode('utf-8')
            print(f"YouTube API é”™è¯¯: {e.code} - {error_body}")
            raise

    def _parse_duration(self, duration_str: str) -> int:
        """è§£æ ISO 8601 æŒç»­æ—¶é—´æ ¼å¼ (PT1H30M) ä¸ºç§’æ•°"""
        if not duration_str:
            return 0
            
        pattern = re.compile(r'P(?:(?P<days>\d+)D)?T(?:(?P<hours>\d+)H)?(?:(?P<minutes>\d+)M)?(?:(?P<seconds>\d+)S)?')
        match = pattern.match(duration_str)
        if not match:
            return 0
            
        parts = match.groupdict()
        time_params = {}
        for name, param in parts.items():
            if param:
                time_params[name] = int(param)
                
        return int(timedelta(**time_params).total_seconds())
    
    def get_video_details(self, video_ids: List[str]) -> Dict[str, dict]:
        """è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼ˆæ—¶é•¿ã€è§‚çœ‹æ¬¡æ•°ç­‰ï¼‰"""
        if not video_ids:
            return {}
            
        # æ¯æ¬¡æœ€å¤šè¯·æ±‚ 50 ä¸ª ID
        results = {}
        for i in range(0, len(video_ids), 50):
            batch_ids = video_ids[i:i+50]
            params = {
                'part': 'contentDetails,statistics,snippet',
                'id': ','.join(batch_ids)
            }
            
            data = self._make_request('videos', params)
            for item in data.get('items', []):
                vid = item.get('id')
                results[vid] = item
                
        return results

    def search_videos(self, query: str, days_ago: int = 30, min_duration_minutes: int = 30) -> List[YouTubeVideo]:
        """æœç´¢è§†é¢‘"""
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        published_after = (datetime.now() - timedelta(days=days_ago)).isoformat() + 'Z'
        
        params = {
            'part': 'snippet',
            'q': query,
            'type': 'video',
            'order': 'date',
            'maxResults': self.max_results * 2,  # è·å–æ›´å¤šä»¥å¤‡è¿‡æ»¤
            'publishedAfter': published_after,
            'relevanceLanguage': 'en',
            'videoDuration': 'long',  # è¿‡æ»¤ > 20åˆ†é’Ÿçš„è§†é¢‘
        }
        
        try:
            data = self._make_request('search', params)
            video_snippets = {}
            video_ids = []
            
            for item in data.get('items', []):
                video_id = item.get('id', {}).get('videoId')
                if not video_id:
                    continue
                video_ids.append(video_id)
                video_snippets[video_id] = item.get('snippet', {})
            
            # è·å–è¯¦ç»†ä¿¡æ¯ä»¥æ£€æŸ¥å…·ä½“æ—¶é•¿
            video_details = self.get_video_details(video_ids)
            
            final_videos = []
            min_duration_seconds = min_duration_minutes * 60
            
            for vid in video_ids:
                if vid not in video_details:
                    continue
                    
                details = video_details[vid]
                content_details = details.get('contentDetails', {})
                statistics = details.get('statistics', {})
                snippet = video_snippets.get(vid, details.get('snippet', {}))
                
                duration_str = content_details.get('duration', '')
                duration_seconds = self._parse_duration(duration_str)
                
                if duration_seconds < min_duration_seconds:
                    continue
                
                # è·å–ç¼©ç•¥å›¾ URL
                thumbnails = snippet.get('thumbnails', {})
                thumbnail_url = thumbnails.get('high', thumbnails.get('default', {})).get('url', '')
                
                video = YouTubeVideo(
                    video_id=vid,
                    title=snippet.get('title', ''),
                    description=snippet.get('description', ''),
                    channel_title=snippet.get('channelTitle', ''),
                    published_at=snippet.get('publishedAt', ''),
                    thumbnail_url=thumbnail_url,
                    duration=duration_str,
                    duration_seconds=duration_seconds,
                    view_count=statistics.get('viewCount')
                )
                final_videos.append(video)
                
                if len(final_videos) >= self.max_results:
                    break
            
            return final_videos
            
        except Exception as e:
            print(f"æœç´¢è§†é¢‘æ—¶å‡ºé”™: {e}")
            return []
    
    def fetch_leader_videos(self, leader_name: str) -> List[YouTubeVideo]:
        """è·å–ç‰¹å®šç§‘æŠ€é¢†è¢–çš„è§†é¢‘"""
        keywords = self.TECH_LEADERS.get(leader_name, [f"{leader_name} interview"])
        
        all_videos = []
        seen_ids = set()
        
        for keyword in keywords[:3]:  # é™åˆ¶æŸ¥è¯¢æ¬¡æ•°
            videos = self.search_videos(keyword, days_ago=60, min_duration_minutes=30)
            for video in videos:
                if video.video_id not in seen_ids:
                    all_videos.append(video)
                    seen_ids.add(video.video_id)
        
        return all_videos
    
    def fetch_recommended_videos(self, max_results: int = 10) -> List[YouTubeVideo]:
        """è·å–çƒ­é—¨ç§‘æŠ€è§†é¢‘ï¼ˆæ¨¡æ‹Ÿä¸»é¡µæ¨èï¼‰"""
        # ä½¿ç”¨ Science & Technology (category 28) çš„çƒ­é—¨è§†é¢‘
        params = {
            'part': 'snippet,contentDetails,statistics',
            'chart': 'mostPopular',
            'regionCode': 'US',
            'videoCategoryId': '28',  # Science & Technology
            'maxResults': max_results * 3, # å¤šè·å–ä¸€äº›ä»¥ä¾¿è¿‡æ»¤æ—¶é•¿
        }
        
        try:
            print(f"æ­£åœ¨è·å–çƒ­é—¨ç§‘æŠ€è§†é¢‘æ¨è...")
            data = self._make_request('videos', params)
            videos = []
            min_duration_seconds = 30 * 60
            
            for item in data.get('items', []):
                snippet = item.get('snippet', {})
                content_details = item.get('contentDetails', {})
                statistics = item.get('statistics', {})
                video_id = item.get('id')
                
                duration_str = content_details.get('duration', '')
                duration_seconds = self._parse_duration(duration_str)
                
                # åŒæ ·åº”ç”¨ 30 åˆ†é’Ÿç­›é€‰
                if duration_seconds < min_duration_seconds:
                    continue
                
                thumbnails = snippet.get('thumbnails', {})
                thumbnail_url = thumbnails.get('high', thumbnails.get('default', {})).get('url', '')
                
                video = YouTubeVideo(
                    video_id=video_id,
                    title=snippet.get('title', ''),
                    description=snippet.get('description', ''),
                    channel_title=snippet.get('channelTitle', ''),
                    published_at=snippet.get('publishedAt', ''),
                    thumbnail_url=thumbnail_url,
                    duration=duration_str,
                    duration_seconds=duration_seconds,
                    view_count=statistics.get('viewCount')
                )
                videos.append(video)
                
                if len(videos) >= max_results:
                    break
            
            return videos
            
        except Exception as e:
            print(f"è·å–æ¨èè§†é¢‘æ—¶å‡ºé”™: {e}")
            return []

    def fetch_all_leaders(self) -> dict:
        """è·å–æ‰€æœ‰ç§‘æŠ€é¢†è¢–çš„è§†é¢‘"""
        result = {}
        
        for leader_name in self.TECH_LEADERS.keys():
            print(f"æ­£åœ¨è·å– {leader_name} çš„è§†é¢‘...")
            result[leader_name] = self.fetch_leader_videos(leader_name)
            print(f"  æ‰¾åˆ° {len(result[leader_name])} ä¸ªè§†é¢‘")
        
        return result
    
    def fetch_selected_leaders(self, leaders: List[str] = None) -> dict:
        """è·å–é€‰å®šç§‘æŠ€é¢†è¢–çš„è§†é¢‘"""
        if leaders is None:
            leaders = ["Elon Musk", "Jensen Huang", "Sam Altman"]
        
        result = {}
        
        for leader_name in leaders:
            if leader_name in self.TECH_LEADERS:
                print(f"æ­£åœ¨è·å– {leader_name} çš„è§†é¢‘...")
                result[leader_name] = self.fetch_leader_videos(leader_name)
                print(f"  æ‰¾åˆ° {len(result[leader_name])} ä¸ªè§†é¢‘")
        
        return result
    
    def print_quota_usage(self):
        """æ‰“å°é…é¢ä½¿ç”¨æƒ…å†µ"""
        print("\nğŸ“Š YouTube API é…é¢ä½¿ç”¨ç»Ÿè®¡:")
        print(f"  æ€»è¯·æ±‚æ¬¡æ•°: {self.request_count}")
        print(f"  æ€»é…é¢æ¶ˆè€—: {self.total_quota_used} units")
        print("  (æ¯æ—¥å…è´¹é…é¢é€šå¸¸ä¸º 10,000 units)")
        print("\n  è¯·æ±‚æ˜ç»†:")
        for log in self.request_log:
            print(f"  - [{log['time']}] {log['endpoint']}: {log['cost']} units")


class YouTubeFetcherNoAPI:
    """
    æ—  API çš„ YouTube è§†é¢‘æ¨èï¼ˆä½¿ç”¨é¢„è®¾åˆ—è¡¨ï¼‰
    å½“æ²¡æœ‰ API å¯†é’¥æ—¶ä½¿ç”¨
    """
    
    # é¢„è®¾çš„é«˜è´¨é‡ç§‘æŠ€è®¿è°ˆé¢‘é“å’Œæ’­æ”¾åˆ—è¡¨
    RECOMMENDED_CHANNELS = {
        "Lex Fridman Podcast": {
            "url": "https://www.youtube.com/@lexfridman",
            "description": "æ·±åº¦ç§‘æŠ€è®¿è°ˆï¼Œç»å¸¸é‡‡è®¿ AI é¢†åŸŸä¸“å®¶",
            "leaders": ["Elon Musk", "Sam Altman", "Mark Zuckerberg", "Jensen Huang"],
        },
        "All-In Podcast": {
            "url": "https://www.youtube.com/@alaboringpodcast",
            "description": "ç§‘æŠ€ã€å•†ä¸šã€æ”¿æ²»è¯é¢˜è®¨è®º",
            "leaders": ["Elon Musk", "David Sacks", "Chamath Palihapitiya"],
        },
        "Bloomberg Technology": {
            "url": "https://www.youtube.com/@BloombergTechnology",
            "description": "ç§‘æŠ€æ–°é—»å’ŒCEOè®¿è°ˆ",
            "leaders": ["Jensen Huang", "Satya Nadella", "Sundar Pichai"],
        },
        "NVIDIA": {
            "url": "https://www.youtube.com/@NVIDIA",
            "description": "NVIDIA å®˜æ–¹é¢‘é“ï¼ŒJensen Huang ä¸»é¢˜æ¼”è®²",
            "leaders": ["Jensen Huang"],
        },
        "TED": {
            "url": "https://www.youtube.com/@TED",
            "description": "TED æ¼”è®²",
            "leaders": ["Various Tech Leaders"],
        },
        "Y Combinator": {
            "url": "https://www.youtube.com/@ycombinator",
            "description": "åˆ›ä¸šå’Œç§‘æŠ€è®¿è°ˆ",
            "leaders": ["Sam Altman", "Various Founders"],
        },
    }
    
    # æ¨èçš„æœç´¢é“¾æ¥
    SEARCH_LINKS = {
        "Elon Musk": "https://www.youtube.com/results?search_query=elon+musk+interview+2025&sp=CAI%253D",
        "Jensen Huang": "https://www.youtube.com/results?search_query=jensen+huang+interview+2025&sp=CAI%253D",
        "Sam Altman": "https://www.youtube.com/results?search_query=sam+altman+interview+2025&sp=CAI%253D",
        "Satya Nadella": "https://www.youtube.com/results?search_query=satya+nadella+interview+2025&sp=CAI%253D",
        "Sundar Pichai": "https://www.youtube.com/results?search_query=sundar+pichai+interview+2025&sp=CAI%253D",
        "Mark Zuckerberg": "https://www.youtube.com/results?search_query=mark+zuckerberg+interview+2025&sp=CAI%253D",
    }
    
    def get_recommendations(self, leaders: List[str] = None) -> dict:
        """è·å–æ¨èå†…å®¹"""
        if leaders is None:
            leaders = ["Elon Musk", "Jensen Huang", "Sam Altman"]
        
        return {
            "channels": self.RECOMMENDED_CHANNELS,
            "search_links": {k: v for k, v in self.SEARCH_LINKS.items() if k in leaders},
            "leaders": leaders,
        }


def get_youtube_fetcher(api_key: Optional[str] = None) -> YouTubeFetcher:
    """è·å– YouTube æŠ“å–å™¨å®ä¾‹"""
    key = api_key or os.getenv('YOUTUBE_API_KEY')
    if key:
        return YouTubeFetcher(api_key=key)
    else:
        print("âš ï¸ æœªè®¾ç½® YOUTUBE_API_KEYï¼Œå°†ä½¿ç”¨æ¨èåˆ—è¡¨æ¨¡å¼")
        return None


if __name__ == "__main__":
    api_key = os.getenv('YOUTUBE_API_KEY')
    
    if api_key:
        fetcher = YouTubeFetcher(api_key=api_key, max_results=5)
        videos = fetcher.fetch_selected_leaders(["Elon Musk", "Jensen Huang"])
        
        for leader, leader_videos in videos.items():
            print(f"\nğŸ¬ {leader} çš„è§†é¢‘ (>30min):")
            for video in leader_videos[:3]:
                print(f"  - {video.title}")
                print(f"    æ—¶é•¿: {video.duration}")
                print(f"    {video.watch_url}")
        
        # è·å–æ¨èè§†é¢‘
        print("\nğŸŒŸ çƒ­é—¨ç§‘æŠ€æ¨è (>30min):")
        recs = fetcher.fetch_recommended_videos(max_results=5)
        for video in recs:
            print(f"  - {video.title}")
            print(f"    æ—¶é•¿: {video.duration}")
            print(f"    {video.watch_url}")
            
        fetcher.print_quota_usage()
        
    else:
        print("æœªè®¾ç½® YOUTUBE_API_KEYï¼Œä½¿ç”¨æ¨èåˆ—è¡¨æ¨¡å¼")
        no_api = YouTubeFetcherNoAPI()
        recommendations = no_api.get_recommendations()
        
        print("\nğŸ“º æ¨èé¢‘é“:")
        for name, info in recommendations["channels"].items():
            print(f"  - {name}: {info['url']}")
        
        print("\nğŸ” æœç´¢é“¾æ¥ (å»ºè®®æ‰‹åŠ¨æ·»åŠ  >20min è¿‡æ»¤):")
        for leader, url in recommendations["search_links"].items():
            print(f"  - {leader}: {url}")
