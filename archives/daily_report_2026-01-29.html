
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f7fa;
        }
        .container {
            background: white;
            border-radius: 16px;
            padding: 40px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.08);
        }
        .header {
            text-align: center;
            padding: 30px 0;
            border-bottom: 3px solid #667eea;
            margin-bottom: 30px;
        }
        .header h1 {
            color: #2d3748;
            margin: 0;
            font-size: 32px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .date {
            color: #718096;
            font-size: 16px;
            margin-top: 10px;
        }
        .briefing-box {
            background: linear-gradient(135deg, #e6fffa 0%, #b2f5ea 100%);
            border-radius: 12px;
            padding: 25px;
            margin-bottom: 40px;
            border-left: 5px solid #38b2ac;
        }
        .briefing-title {
            font-size: 20px;
            font-weight: bold;
            color: #234e52;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
        }
        .section {
            margin: 40px 0;
        }
        .section-header {
            display: flex;
            align-items: center;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 2px solid #e2e8f0;
        }
        .section-icon {
            font-size: 28px;
            margin-right: 15px;
        }
        .section-title {
            font-size: 24px;
            color: #2d3748;
            margin: 0;
        }
        .section-subtitle {
            font-size: 14px;
            color: #718096;
            margin-left: auto;
        }
        /* Paper Cards */
        .paper-card {
            background: #f7fafc;
            border-radius: 12px;
            padding: 20px;
            margin: 15px 0;
            border-left: 4px solid #667eea;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        .paper-card:hover {
            transform: translateX(5px);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.15);
        }
        .paper-card.ad { border-left-color: #48bb78; }
        .paper-title { font-size: 16px; font-weight: 600; margin-bottom: 8px; }
        .paper-title a { color: #2d3748; text-decoration: none; }
        .paper-title a:hover { color: #667eea; }
        .paper-authors { font-size: 13px; color: #718096; margin-bottom: 10px; }
        .paper-summary { font-size: 14px; color: #4a5568; line-height: 1.7; }
        .paper-meta { display: flex; gap: 15px; margin-top: 12px; font-size: 12px; }
        .paper-tag { display: inline-block; padding: 3px 10px; background: #edf2f7; border-radius: 12px; color: #4a5568; }
        
        /* Feed Cards */
        .feed-list { list-style: none; padding: 0; }
        .feed-item {
            padding: 15px;
            border-bottom: 1px solid #edf2f7;
            display: flex;
            flex-direction: column;
        }
        .feed-item:last-child { border-bottom: none; }
        .feed-source { 
            font-size: 12px; 
            text-transform: uppercase; 
            color: #718096; 
            font-weight: bold;
            margin-bottom: 4px;
        }
        .feed-title { font-size: 16px; font-weight: 600; margin-bottom: 5px; }
        .feed-title a { color: #2b6cb0; text-decoration: none; }
        .feed-title a:hover { text-decoration: underline; }
        .feed-date { font-size: 12px; color: #a0aec0; }

        .video-card {
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            border-radius: 12px;
            padding: 20px;
            margin: 15px 0;
            color: white;
        }
        .video-title a { color: #ff6b6b; text-decoration: none; }
        
        .footer {
            margin-top: 50px;
            padding-top: 30px;
            border-top: 2px solid #e2e8f0;
            text-align: center;
            color: #718096;
            font-size: 14px;
        }
        .stats-box {
            background: #f1f5f9;
            border-radius: 8px;
            padding: 15px;
            margin-top: 30px;
            border: 1px solid #e2e8f0;
            text-align: left;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ”¬ AI ç ”ç©¶å‘¨æŠ¥</h1>
            <div class="date">2026å¹´01æœˆ29æ—¥</div>
        </div>
        
        <!-- AI Daily Briefing -->
        <div class="briefing-box">
            <div class="briefing-title">â˜•ï¸ ä»Šæ—¥ AI ç®€æŠ¥</div>
            <div style="color: #2c7a7b; font-size: 15px; line-height: 1.8;">
                <p>æ— æ³•ç”Ÿæˆä»Šæ—¥ç®€æŠ¥ï¼Œè¯·ç›´æ¥é˜…è¯»ä¸‹æ–¹è¯¦ç»†å†…å®¹ã€‚</p>
            </div>
        </div>
        
        <!-- arXiv Papers -->
        <div class="section">
            <div class="section-header">
                <span class="section-icon">ğŸ“š</span>
                <h2 class="section-title">æ ¸å¿ƒè®ºæ–‡ (ArXiv)</h2>
            </div>
            <h3 style="color: #4a5568; margin-top:20px;">ğŸ”¥ å¤§æ¨¡å‹å‰æ²¿</h3>
            
            <div class="paper-card">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.20861v1" target="_blank">Evolutionary Strategies lead to Catastrophic Forgetting in LLMs</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Immanuel Abdi, Akshat Gupta, Micah Mok</div>
                <div class="paper-summary">One of the biggest missing capabilities in current AI systems is the ability to learn continuously after deployment. Implementing such continually learning systems have several challenges, one of which is the large memory requirement of gradient-based algorithms that are used to train state-of-the-art LLMs. Evolutionary Strategies (ES) have recently re-emerged as a gradient-free alternative to traditional learning algorithms and have shown encouraging performance on specific tasks in LLMs. In this paper, we perform a comprehensive analysis of ES and specifically evaluate its forgetting curves when training for an increasing number of update steps. We first find that ES is able to reach performance numbers close to GRPO for math and reasoning tasks with a comparable compute budget. However, and most importantly for continual learning, the performance gains in ES is accompanied by significant forgetting of prior abilities, limiting its applicability for training models online. We also explore the reason behind this behavior and show that the updates made using ES are much less sparse and have orders of magnitude larger $\ell_2$ norm compared to corresponding GRPO updates, explaining the contrasting forgetting curves between the two algorithms. With this study, we aim to highlight the issue of forgetting in gradient-free algorithms like ES and hope to inspire future work to mitigate these issues.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-28</span>
                    <a href="https://arxiv.org/pdf/2601.20861v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.20858v1" target="_blank">When Flores Bloomz Wrong: Cross-Direction Contamination in Machine Translation Evaluation</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ David Tan, Pinzhen Chen, Josef van Genabith</div>
                <div class="paper-summary">Large language models (LLMs) can be benchmark-contaminated, resulting in inflated scores that mask memorization as generalization, and in multilingual settings, this memorization can even transfer to "uncontaminated" languages. Using the FLORES-200 translation benchmark as a diagnostic, we study two 7-8B instruction-tuned multilingual LLMs: Bloomz, which was trained on FLORES, and Llama as an uncontaminated control. We confirm Bloomz's FLORES contamination and demonstrate that machine translation contamination can be cross-directional, artificially boosting performance in unseen translation directions due to target-side memorization. Further analysis shows that recall of memorized references often persists despite various source-side perturbation efforts like paraphrasing and named entity replacement. However, replacing named entities leads to a consistent decrease in BLEU, suggesting an effective probing method for memorization in contaminated models.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-28</span>
                    <a href="https://arxiv.org/pdf/2601.20858v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.20838v1" target="_blank">Reward Models Inherit Value Biases from Pretraining</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Brian Christian, Jessica A. F. Thompson, Elle Michelle Yang</div>
                <div class="paper-summary">Reward models (RMs) are central to aligning large language models (LLMs) with human values but have received less attention than pre-trained and post-trained LLMs themselves. Because RMs are initialized from LLMs, they inherit representations that shape their behavior, but the nature and extent of this influence remain understudied. In a comprehensive study of 10 leading open-weight RMs using validated psycholinguistic corpora, we show that RMs exhibit significant differences along multiple dimensions of human value as a function of their base model. Using the "Big Two" psychological axes, we show a robust preference of Llama RMs for "agency" and a corresponding robust preference of Gemma RMs for "communion." This phenomenon holds even when the preference data and finetuning process are identical, and we trace it back to the logits of the respective instruction-tuned and pre-trained models. These log-probability differences themselves can be formulated as an implicit RM; we derive usable implicit reward scores and show that they exhibit the very same agency/communion difference. We run experiments training RMs with ablations for preference data source and quantity, which demonstrate that this effect is not only repeatable but surprisingly durable. Despite RMs being designed to represent human preferences, our evidence shows that their outputs are influenced by the pretrained LLMs on which they are based. This work underscores the importance of safety and alignment efforts at the pretraining stage, and makes clear that open-source developers' choice of base model is as much a consideration of values as of performance.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-28</span>
                    <a href="https://arxiv.org/pdf/2601.20838v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.20829v1" target="_blank">Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Minwu Kim, Safal Shrestha, Keith Ross</div>
                <div class="paper-summary">Reinforcement Learning with Verifiable Rewards (RLVR) has substantially improved the reasoning abilities of large language models (LLMs), yet training often stalls as problems become saturated. We identify the core challenge as the poor accessibility of informative failures: learning signals exist but are rarely encountered during standard rollouts. To address this, we propose failure-prefix conditioning, a simple and effective method for learning from saturated problems. Rather than starting from the original question, our approach reallocates exploration by conditioning training on prefixes derived from rare incorrect reasoning trajectories, thereby exposing the model to failure-prone states. We observe that failure-prefix conditioning yields performance gains matching those of training on medium-difficulty problems, while preserving token efficiency. Furthermore, we analyze the model's robustness, finding that our method reduces performance degradation under misleading failure prefixes, albeit with a mild trade-off in adherence to correct early reasoning. Finally, we demonstrate that an iterative approach, which refreshes failure prefixes during training, unlocks additional gains after performance plateaus. Overall, our results suggest that failure-prefix conditioning offers an effective pathway to extend RLVR training on saturated problems.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-28</span>
                    <a href="https://arxiv.org/pdf/2601.20829v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.20803v1" target="_blank">Structured Semantic Information Helps Retrieve Better Examples for In-Context Learning in Few-Shot Relation Extraction</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Aunabil Chakma, Mihai Surdeanu, Eduardo Blanco</div>
                <div class="paper-summary">This paper presents several strategies to automatically obtain additional examples for in-context learning of one-shot relation extraction. Specifically, we introduce a novel strategy for example selection, in which new examples are selected based on the similarity of their underlying syntactic-semantic structure to the provided one-shot example. We show that this method results in complementary word choices and sentence structures when compared to LLM-generated examples. When these strategies are combined, the resulting hybrid system achieves a more holistic picture of the relations of interest than either method alone. Our framework transfers well across datasets (FS-TACRED and FS-FewRel) and LLM families (Qwen and Gemma). Overall, our hybrid selection method consistently outperforms alternative strategies and achieves state-of-the-art performance on FS-TACRED and strong gains on a customized FewRel subset.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-28</span>
                    <a href="https://arxiv.org/pdf/2601.20803v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.20796v1" target="_blank">Dissecting Multimodal In-Context Learning: Modality Asymmetries and Circuit Dynamics in modern Transformers</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Yiran Huang, Karsten Roth, Quentin Bouniot</div>
                <div class="paper-summary">Transformer-based multimodal large language models often exhibit in-context learning (ICL) abilities. Motivated by this phenomenon, we ask: how do transformers learn to associate information across modalities from in-context examples? We investigate this question through controlled experiments on small transformers trained on synthetic classification tasks, enabling precise manipulation of data statistics and model architecture. We begin by revisiting core principles of unimodal ICL in modern transformers. While several prior findings replicate, we find that Rotary Position Embeddings (RoPE) increases the data complexity threshold for ICL. Extending to the multimodal setting reveals a fundamental learning asymmetry: when pretrained on high-diversity data from a primary modality, surprisingly low data complexity in the secondary modality suffices for multimodal ICL to emerge. Mechanistic analysis shows that both settings rely on an induction-style mechanism that copies labels from matching in-context exemplars; multimodal training refines and extends these circuits across modalities. Our findings provide a mechanistic foundation for understanding multimodal ICL in modern transformers and introduce a controlled testbed for future investigation.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-28</span>
                    <a href="https://arxiv.org/pdf/2601.20796v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            
            
            <h3 style="color: #4a5568; margin-top:30px;">ğŸ“Š å¹¿å‘Šä¸æ¨èç®—æ³•</h3>
            
            <div class="paper-card ad">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.18251v1" target="_blank">GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Kesha Ou, Zhen Tian, Wayne Xin Zhao</div>
                <div class="paper-summary">Click-through rate (CTR) prediction plays a pivotal role in online advertising and recommender systems. Despite notable progress in modeling user preferences from historical behaviors, two key challenges persist. First, exsiting discriminative paradigms focus on matching candidates to user history, often overfitting to historically dominant features and failing to adapt to rapid interest shifts. Second, a critical information chasm emerges from the point-wise ranking paradigm. By scoring each candidate in isolation, CTR models discard the rich contextual signal implied by the recalled set as a whole, leading to a misalignment where long-term preferences often override the user's immediate, evolving intent. To address these issues, we propose GenCI, a generative user intent framework that leverages semantic interest cohorts to model dynamic user preferences for CTR prediction. The framework first employs a generative model, trained with a next-item prediction (NTP) objective, to proactively produce candidate interest cohorts. These cohorts serve as explicit, candidate-agnostic representations of a user's immediate intent. A hierarchical candidate-aware network then injects this rich contextual signal into the ranking stage, refining them with cross-attention to align with both user history and the target item. The entire model is trained end-to-end, creating a more aligned and effective CTR prediction pipeline. Extensive experiments on three widely used datasets demonstrate the effectiveness of our approach.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-26</span>
                    <a href="https://arxiv.org/pdf/2601.18251v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card ad">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.17836v1" target="_blank">Unleashing the Potential of Sparse Attention on Long-term Behaviors for CTR Prediction</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Weijiang Lai, Beihong Jin, Di Zhang</div>
                <div class="paper-summary">In recent years, the success of large language models (LLMs) has driven the exploration of scaling laws in recommender systems. However, models that demonstrate scaling laws are actually challenging to deploy in industrial settings for modeling long sequences of user behaviors, due to the high computational complexity of the standard self-attention mechanism. Despite various sparse self-attention mechanisms proposed in other fields, they are not fully suited for recommendation scenarios. This is because user behaviors exhibit personalization and temporal characteristics: different users have distinct behavior patterns, and these patterns change over time, with data from these users differing significantly from data in other fields in terms of distribution. To address these challenges, we propose SparseCTR, an efficient and effective model specifically designed for long-term behaviors of users. To be precise, we first segment behavior sequences into chunks in a personalized manner to avoid separating continuous behaviors and enable parallel processing of sequences. Based on these chunks, we propose a three-branch sparse self-attention mechanism to jointly identify users' global interests, interest transitions, and short-term interests. Furthermore, we design a composite relative temporal encoding via learnable, head-specific bias coefficients, better capturing sequential and periodic relationships among user behaviors. Extensive experimental results show that SparseCTR not only improves efficiency but also outperforms state-of-the-art methods. More importantly, it exhibits an obvious scaling law phenomenon, maintaining performance improvements across three orders of magnitude in FLOPs. In online A/B testing, SparseCTR increased CTR by 1.72\% and CPM by 1.41\%. Our source code is available at https://github.com/laiweijiang/SparseCTR.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-25</span>
                    <a href="https://arxiv.org/pdf/2601.17836v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card ad">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.17472v1" target="_blank">Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Junyou He, Lixi Deng, Huichao Guo</div>
                <div class="paper-summary">Cross-domain recommendation (CDR) has been increasingly explored to address data sparsity and cold-start issues. However, recent approaches typically disentangle domain-invariant features shared between source and target domains, as well as domain-specific features for each domain. However, they often rely solely on domain-invariant features combined with target domain-specific features, which can lead to suboptimal performance. To overcome the limitations, this paper presents the Adversarial Alignment and Disentanglement Cross-Domain Recommendation ($A^2DCDR$ ) model, an innovative approach designed to capture a comprehensive range of cross-domain information, including both domain-invariant and valuable non-aligned features. The $A^2DCDR$ model enhances cross-domain recommendation through three key components: refining MMD with adversarial training for better generalization, employing a feature disentangler and reconstruction mechanism for intra-domain disentanglement, and introducing a novel fused representation combining domain-invariant, non-aligned features with original contextual data. Experiments on real-world datasets and online A/B testing show that $A^2DCDR$ outperforms existing methods, confirming its effectiveness and practical applicability. The code is provided at https://github.com/youzi0925/A-2DCDR/tree/main.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-24</span>
                    <a href="https://arxiv.org/pdf/2601.17472v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card ad">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.20307v1" target="_blank">Delayed Feedback Modeling for Post-Click Gross Merchandise Volume Prediction: Benchmark, Insights and Approaches</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Xinyu Li, Sishuo Chen, Guipeng Xv</div>
                <div class="paper-summary">The prediction objectives of online advertisement ranking models are evolving from probabilistic metrics like conversion rate (CVR) to numerical business metrics like post-click gross merchandise volume (GMV). Unlike the well-studied delayed feedback problem in CVR prediction, delayed feedback modeling for GMV prediction remains unexplored and poses greater challenges, as GMV is a continuous target, and a single click can lead to multiple purchases that cumulatively form the label. To bridge the research gap, we establish TRACE, a GMV prediction benchmark containing complete transaction sequences rising from each user click, which supports delayed feedback modeling in an online streaming manner. Our analysis and exploratory experiments on TRACE reveal two key insights: (1) the rapid evolution of the GMV label distribution necessitates modeling delayed feedback under online streaming training; (2) the label distribution of repurchase samples substantially differs from that of single-purchase samples, highlighting the need for separate modeling. Motivated by these findings, we propose RepurchasE-Aware Dual-branch prEdictoR (READER), a novel GMV modeling paradigm that selectively activates expert parameters according to repurchase predictions produced by a router. Moreover, READER dynamically calibrates the regression target to mitigate under-estimation caused by incomplete labels. Experimental results show that READER yields superior performance on TRACE over baselines, achieving a 2.19% improvement in terms of accuracy. We believe that our study will open up a new avenue for studying online delayed feedback modeling for GMV prediction, and our TRACE benchmark with the gathered insights will facilitate future research and application in this promising direction. Our code and dataset are available at https://github.com/alimama-tech/OnlineGMV .</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-28</span>
                    <a href="https://arxiv.org/pdf/2601.20307v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card ad">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.19965v1" target="_blank">Modeling Cascaded Delay Feedback for Online Net Conversion Rate Prediction: Benchmark, Insights and Solutions</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Mingxuan Luo, Guipeng Xv, Sishuo Chen</div>
                <div class="paper-summary">In industrial recommender systems, conversion rate (CVR) is widely used for traffic allocation, but it fails to fully reflect recommendation effectiveness because it ignores refund behavior. To better capture true user satisfaction and business value, net conversion rate (NetCVR), defined as the probability that a clicked item is purchased and not refunded, has been proposed.Unlike CVR, NetCVR prediction involves a more complex multi-stage cascaded delayed feedback process. The two cascaded delays from click to conversion and from conversion to refund have opposite effects, making traditional CVR modeling methods inapplicable. Moreover, the lack of open-source datasets and online continuous training schemes further hinders progress in this area.To address these challenges, we introduce CASCADE (Cascaded Sequences of Conversion and Delayed Refund), the first large-scale open dataset derived from the Taobao app for online continuous NetCVR prediction. Through an in-depth analysis of CASCADE, we identify three key insights: (1) NetCVR exhibits strong temporal dynamics, necessitating online continuous modeling; (2) cascaded modeling of CVR and refund rate outperforms direct NetCVR modeling; and (3) delay time, which correlates with both CVR and refund rate, is an important feature for NetCVR prediction.Based on these insights, we propose TESLA, a continuous NetCVR modeling framework featuring a CVR-refund-rate cascaded architecture, stage-wise debiasing, and a delay-time-aware ranking loss. Extensive experiments demonstrate that TESLA consistently outperforms state-of-the-art methods on CASCADE, achieving absolute improvements of 12.41 percent in RI-AUC and 14.94 percent in RI-PRAUC on NetCVR prediction. The code and dataset are publicly available at https://github.com/alimama-tech/NetCVR.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-27</span>
                    <a href="https://arxiv.org/pdf/2601.19965v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            

            <div class="paper-card ad">
                <div class="paper-title">
                    <a href="https://arxiv.org/abs/2601.19142v1" target="_blank">Length-Adaptive Interest Network for Balancing Long and Short Sequence Modeling in CTR Prediction</a>
                </div>
                <div class="paper-authors">ğŸ‘¥ Zhicheng Zhang, Zhaocheng Du, Jieming Zhu</div>
                <div class="paper-summary">User behavior sequences in modern recommendation systems exhibit significant length heterogeneity, ranging from sparse short-term interactions to rich long-term histories. While longer sequences provide more context, we observe that increasing the maximum input sequence length in existing CTR models paradoxically degrades performance for short-sequence users due to attention polarization and length imbalance in training data. To address this, we propose LAIN(Length-Adaptive Interest Network), a plug-and-play framework that explicitly incorporates sequence length as a conditioning signal to balance long- and short-sequence modeling. LAIN consists of three lightweight components: a Spectral Length Encoder that maps length into continuous representations, Length-Conditioned Prompting that injects global contextual cues into both long- and short-term behavior branches, and Length-Modulated Attention that adaptively adjusts attention sharpness based on sequence length. Extensive experiments on three real-world benchmarks across five strong CTR backbones show that LAIN consistently improves overall performance, achieving up to 1.15% AUC gain and 2.25% log loss reduction. Notably, our method significantly improves accuracy for short-sequence users without sacrificing longsequence effectiveness. Our work offers a general, efficient, and deployable solution to mitigate length-induced bias in sequential recommendation.</div>
                <div class="paper-meta">
                    <span class="paper-tag">ğŸ“… 2026-01-27</span>
                    <a href="https://arxiv.org/pdf/2601.19142v1" class="paper-link" target="_blank">ğŸ“„ PDF</a>
                </div>
            </div>
            
        </div>
        
        <!-- RSS Feeds -->
        <div class="section">
            <div class="section-header">
                <span class="section-icon">ğŸ“¡</span>
                <h2 class="section-title">ä¸šç•ŒåŠ¨æ€</h2>
            </div>
            
            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 40px;">
                <div>
                    <h3 style="border-bottom: 2px solid #ed8936; padding-bottom: 10px; color: #c05621;">ğŸ¢ AI Labs æ›´æ–°</h3>
                    <div class="feed-list">
            <div class="feed-item">
                <div class="feed-source">Google The Keyword</div>
                <div class="feed-title"><a href="https://blog.google/products-and-platforms/products/chrome/gemini-3-auto-browse/" target="_blank">The new era of browsing: Putting Gemini to work in Chrome</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">Google The Keyword</div>
                <div class="feed-title"><a href="https://blog.google/products/ads-commerce/ads-decoded-podcast-collection/" target="_blank">The Ads Decoded Podcast</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">Google The Keyword</div>
                <div class="feed-title"><a href="https://blog.google/products/ads-commerce/launching-ads-decoded-podcast/" target="_blank">Weâ€™re launching the Ads Decoded Podcast to connect advertisers with the people building Google Ads.</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">Google The Keyword</div>
                <div class="feed-title"><a href="https://blog.google/products/ads-commerce/ai-strategies-master-marketing-2026/" target="_blank">Ads Decoded presents three AI strategies to master the future of marketing in 2026.</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">Google The Keyword</div>
                <div class="feed-title"><a href="https://blog.google/products/ads-commerce/ads-decoded-podcast-google-analytics/" target="_blank">The first episode of the Ads Decoded podcast dives into how marketers can leverage analytics and AI for better results.</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">Google The Keyword</div>
                <div class="feed-title"><a href="https://blog.google/products-and-platforms/products/search/search-ai-features-controls/" target="_blank">Our approach to website controls for Search AI features</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">OpenAI</div>
                <div class="feed-title"><a href="https://openai.com/index/the-next-chapter-for-ai-in-the-eu" target="_blank">The next chapter for AI in the EU</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">OpenAI</div>
                <div class="feed-title"><a href="https://openai.com/index/emea-youth-and-wellbeing-grant" target="_blank">EMEA Youth & Wellbeing Grant</a></div>
                <div class="feed-date">01-28</div>
            </div>
            </div>
                </div>
                <div>
                    <h3 style="border-bottom: 2px solid #48bb78; padding-bottom: 10px; color: #2f855a;">ğŸ’° é¡¶çº§é£æŠ•è§‚ç‚¹</h3>
                    <div class="feed-list">
            <div class="feed-item">
                <div class="feed-source">Sequoia Capital</div>
                <div class="feed-title"><a href="https://sequoiacap.com/article/partnering-with-flapping-airplanes/" target="_blank">Partnering With Flapping Airplanes</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">Sequoia Capital</div>
                <div class="feed-title"><a href="https://sequoiacap.com/article/partnering-with-pace-making-work-weightless/" target="_blank">Partnering with Pace: Making Work Weightless</a></div>
                <div class="feed-date">01-27</div>
            </div>
            </div>
                </div>
            </div>
            
            <div style="margin-top: 40px;">
                 <h3 style="border-bottom: 2px solid #4299e1; padding-bottom: 10px; color: #2b6cb0;">ğŸ“° ç§‘æŠ€æ–°é—»ç²¾é€‰</h3>
                 <div class="feed-list">
            <div class="feed-item">
                <div class="feed-source">TechCrunch</div>
                <div class="feed-title"><a href="https://techcrunch.com/2026/01/28/meta-burned-19-billion-on-vr-last-year-and-2026-wont-be-any-better/" target="_blank">Meta burned $19 billion on VR last year, and 2026 wonâ€™t be any better</a></div>
                <div class="feed-date">01-29</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">The Verge</div>
                <div class="feed-title"><a href="https://www.theverge.com/tech/869926/apple-hires-sebastiaan-de-with-design-team-halide-lux" target="_blank">Halide co-founder Sebastiaan de With is joining Apple&#8217;s design team</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">The Verge</div>
                <div class="feed-title"><a href="https://www.theverge.com/news/869882/mark-zuckerberg-meta-earnings-q4-2025" target="_blank">Mark Zuckerberg is all in on AI as the new social media</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">The Verge</div>
                <div class="feed-title"><a href="https://www.theverge.com/news/869889/microsoft-windows-11-1-billion-users" target="_blank">Windows 11 has reached 1 billion users faster than Windows 10</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">TechCrunch</div>
                <div class="feed-title"><a href="https://techcrunch.com/2026/01/28/zuckerberg-teases-agentic-commerce-tools-and-major-ai-rollout-in-2026/" target="_blank">Zuckerberg teases agentic commerce tools and major AI rollout in 2026</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">TechCrunch AI</div>
                <div class="feed-title"><a href="https://techcrunch.com/2026/01/28/zuckerberg-teases-agentic-commerce-tools-and-major-ai-rollout-in-2026/" target="_blank">Zuckerberg teases agentic commerce tools and major AI rollout in 2026</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">TechCrunch</div>
                <div class="feed-title"><a href="https://techcrunch.com/2026/01/28/trump-energy-department-loosens-rules-on-nuclear-safety/" target="_blank">Trump energy department loosens rules on nuclear safety</a></div>
                <div class="feed-date">01-28</div>
            </div>
            
            <div class="feed-item">
                <div class="feed-source">The Verge</div>
                <div class="feed-title"><a href="https://www.theverge.com/transportation/869872/tesla-model-s-model-x-discontinue-optimus-robot-factory" target="_blank">Tesla discontinuing Model S and Model X to make room for robots</a></div>
                <div class="feed-date">01-28</div>
            </div>
            </div>
            </div>
        </div>
        
        <!-- YouTube Videos -->
        <div class="section">
            <div class="section-header">
                <span class="section-icon">ğŸ¬</span>
                <h2 class="section-title">ç§‘æŠ€é¢†è¢–è®¿è°ˆ</h2>
            </div>
            <h4 style="margin: 20px 0 10px 0; color: #553c9a;">ğŸ‘¤ Elon Musk</h4>

                <div class="video-card">
                    <div class="video-title"><a href="https://www.youtube.com/watch?v=IgifEgm1-e0" target="_blank">ğŸ¥ Conversation with Elon Musk | World Economic Forum Annual Meeting 2026</a></div>
                    <div style="font-size: 12px; color: #a0aec0; margin-top:5px;">Please join us for a conversation between Elon Musk, CEO of Tesla; Chief Engineer, SpaceX; CTO, xAI;...</div>
                </div>
                

                <div class="video-card">
                    <div class="video-title"><a href="https://www.youtube.com/watch?v=UrB2tQDVLLo" target="_blank">ğŸ¥ Tesla CEO Elon Musk speaks at the World Economic Forum in Davos, Switzerland â€” 1/22/2026</a></div>
                    <div style="font-size: 12px; color: #a0aec0; margin-top:5px;">Elon Musk, CEO of Tesla; chief engineer of SpaceX; and CTO of xAI joins Laurence D. Fink, chair and ...</div>
                </div>
                
<h4 style="margin: 20px 0 10px 0; color: #553c9a;">ğŸ‘¤ Jensen Huang</h4>

                <div class="video-card">
                    <div class="video-title"><a href="https://www.youtube.com/watch?v=GgMegLZh_IM" target="_blank">ğŸ¥ WEF 2026 LIVE: NVIDIA CEO Jensen Huang At Davos 2026: NVIDIA, AI Power &amp; The Future Of Global Tech</a></div>
                    <div style="font-size: 12px; color: #a0aec0; margin-top:5px;">NVIDIA President and CEO Jensen Huang takes the global stage at the 2026 World Economic Forum in Dav...</div>
                </div>
                

                <div class="video-card">
                    <div class="video-title"><a href="https://www.youtube.com/watch?v=3hptKYix4X8" target="_blank">ğŸ¥ Joe Rogan Experience #2422 - Jensen Huang</a></div>
                    <div style="font-size: 12px; color: #a0aec0; margin-top:5px;">Jensen Huang is the founder, president, and CEO of NVIDIA, the company whose 1999 invention of the G...</div>
                </div>
                
<h4 style="margin: 20px 0 10px 0; color: #553c9a;">ğŸ‘¤ Sam Altman</h4>

                <div class="video-card">
                    <div class="video-title"><a href="https://www.youtube.com/watch?v=_SCs1KQvIJ4" target="_blank">ğŸ¥ ã€å¿…è¦‹ã€‘ã‚µãƒ ã‚¢ãƒ«ãƒˆãƒãƒ³ãŒèªã‚‹ã€ŒGPT-6ã§å¬‰ã—ã„è¨­è¨ˆ vs çµ‚ã‚ã‚‹è¨­è¨ˆã€ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ç”Ÿå­˜æˆ¦ç•¥ã‚’è§£èª¬</a></div>
                    <div style="font-size: 12px; color: #a0aec0; margin-top:5px;">ä»Šå›ã®å‹•ç”»ã§ã¯ã€OpenAIã€ŒTown Hall with Sam Altmanã€ã‚¤ãƒ™ãƒ³ãƒˆã§èªã‚‰ã‚ŒãŸ14ã®ãƒã‚¤ãƒ³ãƒˆã‚’å¾¹åº•è§£èª¬ã—ã¾ã—ãŸã€‚ GPT-6ãŒå‡ºãŸ ......</div>
                </div>
                

                <div class="video-card">
                    <div class="video-title"><a href="https://www.youtube.com/watch?v=luFab5trzBk" target="_blank">ğŸ¥ Elon Musk vs. Sam Altman: Who Will Win the AI War? | 3699 AI Insider Club</a></div>
                    <div style="font-size: 12px; color: #a0aec0; margin-top:5px;">Get Power5 AI: https://aiagencygroup.ai/power5-ai Join my 100k 3699 AI Insider Club for free: https:...</div>
                </div>
                
        </div>
        
        <!-- New Sources: GitHub, Reddit, HN -->
        
            <div class="section">
                <div class="section-header">
                    <span class="section-icon">ğŸŒ</span>
                    <h2 class="section-title">ç¤¾åŒºç²¾é€‰ (AI Curated)</h2>
                </div>
                
            <div style="margin-bottom: 30px;">
                <h3 style="border-bottom: 2px solid #f59e0b; padding-bottom: 10px; color: #d97706;">ğŸ”¥ GitHub è¶‹åŠ¿é¡¹ç›®</h3>
                
                <div style="padding: 10px; border-left: 3px solid #cbd5e0; margin: 8px 0;">
                    <a href="https://github.com/antfu/skills" target="_blank" style="color: #2b6cb0;">
                        antfu/skills
                    </a>
                </div>
                

                <div style="padding: 10px; border-left: 3px solid #cbd5e0; margin: 8px 0;">
                    <a href="https://github.com/tanweai/wooyun-legacy" target="_blank" style="color: #2b6cb0;">
                        tanweai/wooyun-legacy
                    </a>
                </div>
                

                <div style="padding: 10px; border-left: 3px solid #cbd5e0; margin: 8px 0;">
                    <a href="https://github.com/m1heng/clawdbot-feishu" target="_blank" style="color: #2b6cb0;">
                        m1heng/clawdbot-feishu
                    </a>
                </div>
                
            </div>
            
            <div style="margin-bottom: 30px;">
                <h3 style="border-bottom: 2px solid #f97316; padding-bottom: 10px; color: #ea580c;">ğŸŸ  Hacker News ç²¾é€‰</h3>
                
                <div style="padding: 10px; border-left: 3px solid #cbd5e0; margin: 8px 0;">
                    <a href="https://news.ycombinator.com/item?id=46803356" target="_blank" style="color: #2b6cb0;">
                        Please Don't Say Mean Things about the AI I Just Invested a Billion Dollars In
                    </a>
                </div>
                

                <div style="padding: 10px; border-left: 3px solid #cbd5e0; margin: 8px 0;">
                    <a href="https://news.ycombinator.com/item?id=46789561" target="_blank" style="color: #2b6cb0;">
                        Trinity large: An open 400B sparse MoE model
                    </a>
                </div>
                

                <div style="padding: 10px; border-left: 3px solid #cbd5e0; margin: 8px 0;">
                    <a href="https://news.ycombinator.com/item?id=46795908" target="_blank" style="color: #2b6cb0;">
                        Airfoil (2024)
                    </a>
                </div>
                
            </div>
            
            </div>
            
        
        
        <div class="stats-box">
            <h4 style="margin:0 0 10px 0; color:#4a5568;">âš™ï¸ ç³»ç»Ÿè¿è¡Œç»Ÿè®¡</h4>
            <div style="display:flex; justify-content:space-between; font-size:12px; color:#718096;">
                <div>
                    <strong>ğŸ¤– AI æ¨¡å‹ (Qwen-72B)</strong><br>
                    è°ƒç”¨æ¬¡æ•°: 0<br>
                    Input Tokens: 0<br>
                    Output Tokens: 0
                </div>
                <div>
                    <strong>ğŸ¬ YouTube API</strong><br>
                    API è°ƒç”¨: 17<br>
                    Quota æ¶ˆè€—: 908 units
                </div>
            </div>
        </div>
        
        
        <div class="footer">
            <p>ğŸ“… 2026å¹´01æœˆ29æ—¥ | Daily Info System</p>
            <p>ğŸ’¡ Stay Hungry, Stay Foolish</p>
        </div>
    </div>
</body>
</html>
